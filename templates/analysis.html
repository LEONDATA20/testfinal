<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Myers-Briggs Type Indicator Analysis</title>
  <link href='https://fonts.googleapis.com/css?family=Pacifico' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Arimo' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Hind:300' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <script src="https://d3js.org/d3.v5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/5.0.0/math.min.js"></script>
  <style>
    #table-area {
      margin-right: -10px;
      width:1000px;
    }

    #bbb {
      padding-left: 50px;
      padding-right: 50px;
    }

  </style>
  
</head>


<body>
  <div>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark" id="bbb">
        <div class="container-fluid">
          <a class="navbar-brand" href="/">Myers-Briggs Personality Indicator</a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse justify-content-end" id="navbarNavDropdown">
              <ul class="navbar-nav ">
                <li class="nav-item dropdown active">
                  <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  Learn More
                  </a>
                  <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
                    <a class="dropdown-item" href= "/" target="_blank">Background</a>
                    <a class="dropdown-item" href={{url_for('analysis', filename='analysis.html') }} target="_blank">Analysis</a>
                    <a class="dropdown-item" href={{ url_for('results', filename='results.html') }} target="_blank">Results</a>
                  </div>
                </li>
                <li class="nav-item">
                  <a class="nav-link" target="_blank" href={{ url_for('predict', filename='prediction.html') }}>Predict</a>
                </li>
              </ul>
          </div>
        </div>  
    </nav>
  
    <div class="box box-content">
      <div class="container">
        <div class="row">
          <div class="table-responsive-lg" >
            <br>
            <div class="container table-responsive-lg">
              <br>
              <h4>Methodology</h4>
              <br>
              <img class="d-block w-100" src='image/Images/flowchart-methodology overview.png' alt="Flowchart">
              <br>
              <p class="text-justify">The goal of our project is to try to predict the personality type of individuals based on some text input.</p>
              <p class="text-justify">The dataset contains over 8600 rows and has 2 columns: type of Myers-Briggs personality 4-letter code and section of each of the last 50 things posted. The classification methods used to train and test the data were: </p>
              <li>Neural Networks</li>
              <li>Random Forests</li>
              <li>Support Vector Machine (SVM)</li>
              <li>k-nearest neighbors (KNN)</li>
              <li>Binomial Naïve Bayes.</li>
              <br>
              <p class="text-justify">This data was collected through the PersonalityCafe forum, as it provides a large selection of people and their MBTI personality type, as well as what they have written.</p>
              <p class="text-justify">We first determined that it would be beneficial to extract key findings from our heavily texted data. We focused on capturing features such as number of words per post, the punctuation used as well as made use of a sentiment analysis to determine polarity and subjectivity in the text. Sentiment determines the ‘positivity’ or ‘negativity’ of a piece of writing. We used the TextBlob library to process the comments in our dataset and determine the sentiment for each row. Sentiment is rated from -1.0 to 1.0, where -1.0 is the most negative and 1.0 is most positive.</p>
              <p class="text-justify">We began generating our models and quickly realized that our data was severely imbalanced in personality type, also identifying that the 16 different categories was affecting our accuracy scores. We then decided to divide our personality types from 16 different categories into 2 categories. We wanted to focus on predicting whether a post was from an introverted personality or an extroverted personality.</p>
              <p class="text-justify">We then tried calculating the accuracy for each category to compare if our model would be able to accurately predict if a post is Intuitive or Sensing, Feeling or Thinking, Judging or Perceiving. We later found out that the Neural Network model was best able to predict scores in all categories with the most accurate being in Intuition – Sensing and a close second being Introversion – Extroversion.</p>
              <p class="text-justify">Finally, we visualized the results in Tableau and designed a webpage for the users to interact with and hosted it through Heroku.</p>
            </div>
            <br>
            <div class="container-fluid">
                <h4>Analysis</h4>
                <hr>
                <p class="text-justify">Once we trained and tested all the selected models, we got the accuracy scores between 13 to 20% for all 16 categories.</p>
                <p class="text-justify">For the model using the algorithm for Multinomial Naïve Bayes, the comments were used as y and the type as x, since the assumption for this algorithm is that all features are statistically independent. The accuracy score of 20.60% was achieved.</p>
                <p class="text-justify">For the remaining models’ multiple features were taken into account:</p>
                <li>Words per comment</li>
                <li>Questions per comment</li>
                <li>Exclamations per comment</li>
                <li>Usage of uppercase </li>
                <li>The polarity and subjectivity of the comment</li>
                <li>Usage of emojis </li>
                <li>Ellipsis per comment</li>
                <br>
                <p class="text-justify">Out of all the models, Neural networks had the best accuracy of 24.11% followed by support vector machine with accuracy of 22%. The other model of random forests gave an accuracy score of 19.87% while KNN gave an accuracy of 13.24%. This is possibly due to the fact that the data is very limited for most categories with INFP having maximum entries (1832) and ESTJ with only 39 entries. This imbalance in the datapoints for every category could cause issues wherein the model would not be able to predict the category with very less data. Since we use random split, if there is such a huge imbalance there is a possibility that the training dataset would not have any of the category with least amount of entries and hence the model would be unable to predict that particular category on the test dataset.</p>
                <p class="text-justify">The multiple factors taken into consideration while training the models could have possibly given better scores in these models as compared to the Multinomial Naïve Bayes which considered only the comments as a whole.</p>
                <p class="text-justify">Having analysed the individual four categories, higher accuracy scores were achieved when a particular preference was taken into consideration. Most models predicted the preferences of intuition/sensing with the highest accuracy score of over 80%. This was followed closely by the category introversion/extraversion with accuracy in the range of 70-80%. We decided to use these two categories for prediction because of better accuracy scores so our users could relate with the same. The Neural Network model gave the highest accuracy for these 2 categories and hence was chosen to predict the personality preferences based on the input received from the users.</p>

            </div>  
            <br>
            <br>
          </div>
        </div>
      </div>
    </div>
  </div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/4.11.0/d3.js"></script>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</body>

<footer class="page-footer font-small blue fixed-bottom">
        <p>Copyright Hephzibah, Leon, Olivia & Shibani &#169; 2020 All rights reserved</p>   
    <style>
      footer{
        background-color: #353a40; 
        border-top-style: solid; 
        border-top-color: #034946;
        color: white; 
        min-height: 20px; 
        font-family: Arial, Helvetica, sans-serif;
        font-size: 10px; 
        text-align: center; 
        left: 0;
        bottom: 0;
        width: 100%;
        position: relative}
    </style>
</footer>

</html>
